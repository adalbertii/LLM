{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install compress_pickle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv2Zeuc8fRes",
        "outputId": "418e5c28-72b8-4bc1-c709-0d4ebfe05f85"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: compress_pickle in /usr/local/lib/python3.10/dist-packages (2.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip  install deepparse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjICjK0HfbsC",
        "outputId": "28c81c64-adf6-4d3e-beb7-51c1445a3555"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepparse in /usr/local/lib/python3.10/dist-packages (0.9.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepparse) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepparse) (2.2.1+cu121)\n",
            "Requirement already satisfied: bpemb in /usr/local/lib/python3.10/dist-packages (from deepparse) (0.3.5)\n",
            "Requirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from deepparse) (4.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from deepparse) (2.31.0)\n",
            "Requirement already satisfied: fasttext-wheel in /usr/local/lib/python3.10/dist-packages (from deepparse) (0.9.2)\n",
            "Requirement already satisfied: pymagnitude-light in /usr/local/lib/python3.10/dist-packages (from deepparse) (0.1.147)\n",
            "Requirement already satisfied: poutyne in /usr/local/lib/python3.10/dist-packages (from deepparse) (1.17.1)\n",
            "Requirement already satisfied: pandas==2.0.3 in /usr/local/lib/python3.10/dist-packages (from deepparse) (2.0.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from deepparse) (2.0.7)\n",
            "Requirement already satisfied: cloudpathlib[azure,gs,s3] in /usr/local/lib/python3.10/dist-packages (from deepparse) (0.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->deepparse) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->deepparse) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->deepparse) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.0.0->deepparse) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.0.0->deepparse) (6.4.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bpemb->deepparse) (0.1.99)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bpemb->deepparse) (4.66.2)\n",
            "Requirement already satisfied: typing_extensions>4 in /usr/local/lib/python3.10/dist-packages (from cloudpathlib[azure,gs,s3]->deepparse) (4.11.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from cloudpathlib[azure,gs,s3]->deepparse) (2.8.0)\n",
            "Requirement already satisfied: azure-storage-blob>=12 in /usr/local/lib/python3.10/dist-packages (from cloudpathlib[azure,gs,s3]->deepparse) (12.19.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from cloudpathlib[azure,gs,s3]->deepparse) (1.34.84)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel->deepparse) (2.12.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext-wheel->deepparse) (67.7.2)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (from poutyne->deepparse) (1.3.2)\n",
            "Requirement already satisfied: fasteners>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from pymagnitude-light->deepparse) (0.19)\n",
            "Requirement already satisfied: lz4>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pymagnitude-light->deepparse) (4.3.3)\n",
            "Requirement already satisfied: xxhash>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pymagnitude-light->deepparse) (3.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->deepparse) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->deepparse) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->deepparse) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepparse) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepparse) (12.4.127)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.28.0 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob>=12->cloudpathlib[azure,gs,s3]->deepparse) (1.30.1)\n",
            "Requirement already satisfied: cryptography>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob>=12->cloudpathlib[azure,gs,s3]->deepparse) (42.0.5)\n",
            "Requirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from azure-storage-blob>=12->cloudpathlib[azure,gs,s3]->deepparse) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.3->deepparse) (1.16.0)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.84 in /usr/local/lib/python3.10/dist-packages (from boto3->cloudpathlib[azure,gs,s3]->deepparse) (1.34.84)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->cloudpathlib[azure,gs,s3]->deepparse) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->cloudpathlib[azure,gs,s3]->deepparse) (0.10.1)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->cloudpathlib[azure,gs,s3]->deepparse) (2.27.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->cloudpathlib[azure,gs,s3]->deepparse) (2.11.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->cloudpathlib[azure,gs,s3]->deepparse) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->cloudpathlib[azure,gs,s3]->deepparse) (2.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepparse) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepparse) (1.3.0)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics->poutyne->deepparse) (24.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics->poutyne->deepparse) (0.11.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.1.4->azure-storage-blob>=12->cloudpathlib[azure,gs,s3]->deepparse) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->cloudpathlib[azure,gs,s3]->deepparse) (1.63.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->cloudpathlib[azure,gs,s3]->deepparse) (3.20.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage->cloudpathlib[azure,gs,s3]->deepparse) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage->cloudpathlib[azure,gs,s3]->deepparse) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage->cloudpathlib[azure,gs,s3]->deepparse) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage->cloudpathlib[azure,gs,s3]->deepparse) (1.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.1.4->azure-storage-blob>=12->cloudpathlib[azure,gs,s3]->deepparse) (2.22)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage->cloudpathlib[azure,gs,s3]->deepparse) (0.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "j5nY4JcnVEu4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import compress_pickle\n",
        "import pickle\n",
        "from deepparse import download_from_public_repository\n",
        "from deepparse.dataset_container import PickleDatasetContainer\n",
        "from deepparse.parser import AddressParser\n",
        "import shutil\n",
        "from poutyne import set_seeds\n",
        "import poutyne\n",
        "import timeit\n",
        "\n",
        "seed = 42\n",
        "set_seeds(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Retrain an Address Parser for Single Country Uses"
      ],
      "metadata": {
        "id": "25k61ikbVEu5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXRz_H4OVEu6"
      },
      "source": [
        "In this example, we will retrain a pre-trained model to maximize its performance for specific countries (e.g. the UK or Canada)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtEyzjnuVEu8"
      },
      "source": [
        "## Retrain a Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYXzaDdOVEu8"
      },
      "source": [
        "First, to retrain our supervised model, we need parsed address example, as shown in the following figure. Fortunately, we have access to a public dataset of such parsed examples, the [Structured Multinational Address Dataset](https://github.com/GRAAL-Research/deepparse-address-data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci5HaCo_VEu9"
      },
      "source": [
        "![parsing](https://github.com/GRAAL-Research/deepparse/blob/master/docs/source/_static/img/address_parsing.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrWdeODXVEu9"
      },
      "source": [
        "For our example, we will focus on UK addresses since we want to parse addresses only from the UK. So let's first download the dataset directly from the public repository using Deepparse `download_from_public_repository` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_dJL9fxDVEu-"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"dataset\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_from_public_repository(\"dataset/data\", \"\", file_extension=\"zip\")"
      ],
      "metadata": {
        "id": "s--0Uu_mgEpN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4uScuG8VEu_"
      },
      "source": [
        "The dataset archive is a zip directory of subdirectories in which each country's data is compressed into an LZMA file (a more aggressive compression algorithm). The dataset public repository offers a [script](https://github.com/GRAAL-Research/deepparse-address-data/blob/main/lzma_decompress.py) to decompress the LZMA compress dataset zip archive. We will use the basic idea of it to decompress the dataset in the next code cell (the script handles CLI parameters)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "xe-9ZTuK-E-f",
        "outputId": "78749dfa-0efb-461a-c7f0-ea5474469024",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NoSizABKVEvA"
      },
      "outputs": [],
      "source": [
        "# First, let's decompress the archive\n",
        "archive_root_path = os.path.join(\"dataset\")\n",
        "archive_path = os.path.join(archive_root_path, \"data.zip\")\n",
        "\n",
        "# Unzip the archive\n",
        "shutil.unpack_archive(archive_path, archive_root_path)\n",
        "\n",
        "# Delete the archive\n",
        "os.remove(archive_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jLwJWufmVEvB"
      },
      "outputs": [],
      "source": [
        "# The script functions with minor modification to handle argument\n",
        "# instead or CLI parsed argument\n",
        "\n",
        "\n",
        "# Function to handle the files paths\n",
        "def absolute_file_paths(directory):\n",
        "    \"\"\"\n",
        "    Function to get all the absolute paths of files into a directory.\n",
        "    \"\"\"\n",
        "    for dir_path, _, filenames in os.walk(directory):\n",
        "        for f in filenames:\n",
        "            if f.endswith(\".lzma\"):\n",
        "                yield os.path.abspath(os.path.join(dir_path, f))\n",
        "\n",
        "\n",
        "# Function to LZMA decompress the files_directory into the path_to_save directory\n",
        "def lzma_decompress(files_directory, root_path_to_save) -> None:\n",
        "    \"\"\"\n",
        "    Script to decompress the dataset from LZMA compress files into pickled one.\n",
        "    \"\"\"\n",
        "    paths = absolute_file_paths(files_directory)\n",
        "\n",
        "    for path in paths:\n",
        "        pickled_data = compress_pickle.load(path, compression=\"lzma\")\n",
        "        filename = path.split(os.path.sep)[-1].replace(\".lzma\", \".p\")\n",
        "        file_path = os.path.join(*path.split(os.path.sep)[-4:-1])\n",
        "        path_to_save = os.path.join(root_path_to_save, file_path)\n",
        "        os.makedirs(path_to_save, exist_ok=True)\n",
        "        with open(os.path.join(path_to_save, filename), \"wb\") as file:\n",
        "            pickle.dump(pickled_data, file)\n",
        "        os.remove(path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V1aK4lhSk4s-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cGHjjHstVEvC"
      },
      "outputs": [],
      "source": [
        "# Let's decompress the dataset. It takes several minutes to decompress.\n",
        "\n",
        "root_dir = os.path.join(\"dataset\", \"data\")\n",
        "clean_root_dir = os.path.join(root_dir, \"clean_data\")\n",
        "clean_train_directory = os.path.join(clean_root_dir, \"train\")\n",
        "clean_test_directory = os.path.join(clean_root_dir, \"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7JUj9wk2VEvC"
      },
      "outputs": [],
      "source": [
        "# We decompress all the dataset\n",
        "lzma_decompress(root_dir, \"dataset\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdDIIlQfVEvC"
      },
      "source": [
        "Now, let's import our train and test datasets into memory to retrain our parser model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BzwC1WbUVEvD"
      },
      "outputs": [],
      "source": [
        "clean_root_dir = os.path.join(root_dir, \"clean_data\")\n",
        "clean_train_directory = os.path.join(clean_root_dir, \"train\")\n",
        "clean_test_directory = os.path.join(clean_root_dir, \"test\")\n",
        "\n",
        "pl_training_data_path = os.path.join(clean_train_directory, \"pl.p\")\n",
        "pl_test_data_path = os.path.join(clean_test_directory, \"pl.p\")\n",
        "\n",
        "training_container = PickleDatasetContainer(pl_training_data_path)\n",
        "test_container = PickleDatasetContainer(pl_test_data_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14bYZCs3VEvD"
      },
      "source": [
        "We will use the FastText one for our base pre-trained model since it is faster to retrain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcR_Ir_DVEvD",
        "outputId": "9a468554-a22a-4e72-aa74-ffc76aa0b330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deepparse/network/seq2seq.py:102: UserWarning: No pre-trained model where found in the cache directory /root/.cache/deepparse. Thus, we willautomatically download the pre-trained model.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading the pre-trained weights for the network fasttext.\n",
            "The fastText pretrained word embeddings will be downloaded (6.8 GO), this process will take several minutes.\n",
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.fr.300.bin.gz\n",
            "(100.00%) [==================================================>]\n",
            "Loading the embeddings model\n"
          ]
        }
      ],
      "source": [
        "address_parser = AddressParser(model_type=\"fasttext\", device=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pghrZne-VEvE"
      },
      "source": [
        "But first, let's see what the performance is before retraining."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJkD3SjxVEvE",
        "outputId": "b8d53632-f4b6-436c-cfa1-2a2e15d960fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 1796/1796 100.00% |████████████████████|ETA: 0.00s test_loss: 0.035425 test_accuracy: 100.000000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rTest steps: 1796 30m13.08s test_loss: 0.137768 test_accuracy: 99.637872                               \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'time': 1813.0773357389999,\n",
              " 'test_loss': 0.1377678936901547,\n",
              " 'test_accuracy': 99.63787163770765}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "address_parser.test(test_container, batch_size=256)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yzdpGN-H2fIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu1pokS1VEvG",
        "outputId": "c12a48fe-b042-41ba-d59f-436d58720691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5 Train steps: 2500 Val steps: 625 1m12.85s loss: 0.068997 accuracy: 99.727499 val_loss: 0.074176 val_accuracy: 99.704808\n",
            "Epoch 1: val_loss improved from inf to 0.07418, saving file to /content/drive/MyDrive/dane/modele/DEEPPARSER/pl_retrain/checkpoint_epoch_1.ckpt\n",
            "Epoch: 2/5 Train steps: 2500 Val steps: 625 1m10.55s loss: 0.065163 accuracy: 99.741057 val_loss: 0.071739 val_accuracy: 99.719749\n",
            "Epoch 2: val_loss improved from 0.07418 to 0.07174, saving file to /content/drive/MyDrive/dane/modele/DEEPPARSER/pl_retrain/checkpoint_epoch_2.ckpt\n",
            "Epoch: 3/5 Train steps: 2500 Val steps: 625 1m12.18s loss: 0.062108 accuracy: 99.750257 val_loss: 0.070241 val_accuracy: 99.724146\n",
            "Epoch 3: val_loss improved from 0.07174 to 0.07024, saving file to /content/drive/MyDrive/dane/modele/DEEPPARSER/pl_retrain/checkpoint_epoch_3.ckpt\n",
            "Epoch: 4/5 Train steps: 2500 Val steps: 625 1m10.97s loss: 0.059310 accuracy: 99.766909 val_loss: 0.067749 val_accuracy: 99.741775\n",
            "Epoch 4: val_loss improved from 0.07024 to 0.06775, saving file to /content/drive/MyDrive/dane/modele/DEEPPARSER/pl_retrain/checkpoint_epoch_4.ckpt\n",
            "Epoch: 5/5 Train steps: 2500 Val steps: 625 1m10.78s loss: 0.057671 accuracy: 99.772406 val_loss: 0.067706 val_accuracy: 99.736088\n",
            "Epoch 5: val_loss improved from 0.06775 to 0.06771, saving file to /content/drive/MyDrive/dane/modele/DEEPPARSER/pl_retrain/checkpoint_epoch_5.ckpt\n",
            "Restoring data from /content/drive/MyDrive/dane/modele/DEEPPARSER/pl_retrain/checkpoint_epoch_5.ckpt\n"
          ]
        }
      ],
      "source": [
        "_ = address_parser.retrain(\n",
        "    training_container,\n",
        "    train_ratio=0.8,\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    num_workers=2,\n",
        "    learning_rate=0.001,\n",
        "    logging_path=\"/content/drive/MyDrive/dane/modele/DEEPPARSER/pl_retrain\",\n",
        "    name_of_the_retrain_parser=\"PLParser\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "adres= AddressParser(model_type=\"fasttext\", device=0, path_to_retrained_model='/content/drive/MyDrive/dane/modele/DEEPPARSER/pl_retrain/PLParser.ckpt')"
      ],
      "metadata": {
        "id": "-fTXNzB1JLI2",
        "outputId": "f4cb903b-c864-4597-b458-3a5aea028e6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the embeddings model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpfefM6-VEvH",
        "outputId": "2c40e7a2-6c3c-4725-9370-fd901be755e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running test\n",
            "\u001b[35mTest steps: \u001b[36m57 \u001b[32m1.74s \u001b[35mtest_loss:\u001b[94m 0.120875\u001b[35m test_accuracy:\u001b[94m 99.575062\u001b[0m                                                \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'time': 1.7367468271404505,\n",
              " 'test_loss': 0.12087451704787924,\n",
              " 'test_accuracy': 99.5750624169449}"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "address_parser.test(test_container, batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oUBiFrjVEvH"
      },
      "source": [
        "To further improve performance, we could train for longer, increase the training dataset size (the actual size of 100,000 addresses), or rework the Seq2Seq hidden sizes. See the [retrain interface documentation](https://deepparse.org/parser.html#deepparse.parser.AddressParser.retrain) for all the training parameters."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "addres_parsed = adres(\"Dzikiego Wina 1, 05-500 Józefosław, Mazowieckie\")\n",
        "print(addres_parsed)"
      ],
      "metadata": {
        "id": "hb7yyBz6_cTi",
        "outputId": "bcd8e309-c20c-4442-e370-4ce8bc71c36e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The unparsed address is 'Dzikiego Wina 1, 05-500 Józefosław, Mazowieckie' and the parsed address is '('dzikiego', 'StreetName') ('wina', 'StreetName') ('1', 'StreetNumber') ('05-500', 'PostalCode') ('józefosław', 'Municipality') ('mazowieckie', 'Province')'\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}